{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"data_preprocessing.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"wkJ5ShIgceqI","outputId":"6e42553e-e3f5-4905-f051-784266a25626","executionInfo":{"status":"ok","timestamp":1566197402755,"user_tz":-480,"elapsed":41641,"user":{"displayName":"Suqi Ling","photoUrl":"","userId":"17227442033461168733"}},"colab":{"base_uri":"https://localhost:8080/","height":702}},"source":["#===从GCS加载数据\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","project_id = 'amazing-firefly-153908'\n","bucket_name = 'nlp_final'\n","\n","# 获取授权\n","from google.colab import auth\n","auth.authenticate_user()\n","\n","#从GCS下载数据至tmp\n","from googleapiclient.discovery import build\n","gcs_service = build('storage', 'v1')\n","from apiclient.http import MediaIoBaseDownload\n","\n","# with open('/tmp/train.csv', 'wb') as f:\n","#   request = gcs_service.objects().get_media(bucket=bucket_name,\n","#                                             object='train.csv')\n","#   media = MediaIoBaseDownload(f, request)\n","\n","#   done = False\n","#   while not done:\n","#     # _ is a placeholder for a progress object that we ignore.\n","#     # (Our file is small, so we skip reporting progress.)\n","#     _, done = media.next_chunk()\n","\n","# with open('/tmp/test.csv', 'wb') as f:\n","#   request = gcs_service.objects().get_media(bucket=bucket_name,\n","#                                             object='test.csv')\n","#   media = MediaIoBaseDownload(f, request)\n","\n","#   done = False\n","#   while not done:\n","#     # _ is a placeholder for a progress object that we ignore.\n","#     # (Our file is small, so we skip reporting progress.)\n","#     _, done = media.next_chunk()\n","    \n","# print('Download complete')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0819 06:50:02.424576 140022735243136 lazy_loader.py:50] \n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","W0819 06:50:03.619950 140022735243136 __init__.py:44] file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 36, in autodetect\n","    from google.appengine.api import memcache\n","ModuleNotFoundError: No module named 'google.appengine'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n","    from oauth2client.contrib.locked_file import LockedFile\n","ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n","    from oauth2client.locked_file import LockedFile\n","ModuleNotFoundError: No module named 'oauth2client.locked_file'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 41, in autodetect\n","    from . import file_cache\n","  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n","    'file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth')\n","ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n","W0819 06:50:03.645776 140022735243136 _default.py:280] No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"gEUSW2C1mptH","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import re\n","from string import punctuation\n","\n","# train = pd.read_csv('/tmp/train.csv')\n","# test = pd.read_csv('/tmp/test.csv')\n","# train.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Fyp3G3QqJgT","colab_type":"code","outputId":"63b5da2e-4fff-4086-be82-21d4e1400560","executionInfo":{"status":"ok","timestamp":1566053329910,"user_tz":-480,"elapsed":696,"user":{"displayName":"Suqi Ling","photoUrl":"","userId":"17227442033461168733"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["# x_train = train[['id','question1', 'question2']]\n","# x_test = test\n","# x_train.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>question1</th>\n","      <th>question2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>What is the step by step guide to invest in sh...</td>\n","      <td>What is the step by step guide to invest in sh...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n","      <td>What would happen if the Indian government sto...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>How can I increase the speed of my internet co...</td>\n","      <td>How can Internet speed be increased by hacking...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Why am I mentally very lonely? How can I solve...</td>\n","      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Which one dissolve in water quikly sugar, salt...</td>\n","      <td>Which fish would survive in salt water?</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id  ...                                          question2\n","0   0  ...  What is the step by step guide to invest in sh...\n","1   1  ...  What would happen if the Indian government sto...\n","2   2  ...  How can Internet speed be increased by hacking...\n","3   3  ...  Find the remainder when [math]23^{24}[/math] i...\n","4   4  ...            Which fish would survive in salt water?\n","\n","[5 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"20eob9ZJeQ1e","colab_type":"code","colab":{}},"source":["#转为小写、清除特殊符号、将一些常见同义词转换统一、去除标点\n","#来自 https://www.kaggle.com/benjaminkz/quora-question-pairs-xgboost/notebook\n","\n","def common_words_transformation_remove_punctuation(text):\n","    \n","    text = text.lower()\n","    \n","    text = re.sub(r\"what's\", \"what is\", text)\n","    text = re.sub(r\"who's\", \"who is\", text)\n","    text = re.sub(r\"where's\", \"where is\", text)\n","    text = re.sub(r\"when's\", \"when is\", text)\n","    text = re.sub(r\"how's\", \"how is\", text)\n","    text = re.sub(r\"it's\", \"it is\", text)\n","    text = re.sub(r\"he's\", \"he is\", text)\n","    text = re.sub(r\"she's\", \"she is\", text)\n","    text = re.sub(r\"that's\", \"that is\", text)\n","    text = re.sub(r\"there's\", \"there is\", text)\n","\n","    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n","    text = re.sub(r\"\\'s\", \" \", text)  # 除了上面的特殊情况外，“\\'s”只能表示所有格，应替换成“ ”\n","    text = re.sub(r\"\\'ve\", \" have \", text)\n","    text = re.sub(r\"can't\", \"can not \", text)\n","    text = re.sub(r\"n't\", \" not \", text)\n","    text = re.sub(r\"i'm\", \"i am\", text)\n","    text = re.sub(r\" m \", \" am \", text)\n","    text = re.sub(r\"\\'re\", \" are \", text)\n","    text = re.sub(r\"\\'d\", \" would \", text)\n","    text = re.sub(r\"\\'ll\", \" will \", text)\n","    text = re.sub(r\"60k\", \" 60000 \", text)\n","    text = re.sub(r\" e g \", \" eg \", text)\n","    text = re.sub(r\" b g \", \" bg \", text)\n","    text = re.sub(r\"\\0s\", \"0\", text)\n","    text = re.sub(r\" 9 11 \", \"911\", text)\n","    text = re.sub(r\"e-mail\", \"email\", text)\n","    text = re.sub(r\"\\s{2,}\", \" \", text)\n","    text = re.sub(r\"quikly\", \"quickly\", text)\n","    text = re.sub(r\" usa \", \" america \", text)\n","    text = re.sub(r\" u s \", \" america \", text)\n","    text = re.sub(r\" uk \", \" england \", text)\n","    text = re.sub(r\"imrovement\", \"improvement\", text)\n","    text = re.sub(r\"intially\", \"initially\", text)\n","    text = re.sub(r\" dms \", \"direct messages \", text)  \n","    text = re.sub(r\"demonitization\", \"demonetization\", text) \n","    text = re.sub(r\"actived\", \"active\", text)\n","    text = re.sub(r\"kms\", \" kilometers \", text)\n","    text = re.sub(r\" cs \", \" computer science \", text)\n","    text = re.sub(r\" ds \", \" data science \", text)\n","    text = re.sub(r\" ee \", \" electronic engineering \", text)\n","    text = re.sub(r\" upvotes \", \" up votes \", text)\n","    text = re.sub(r\" iphone \", \" phone \", text)\n","    text = re.sub(r\"\\0rs \", \" rs \", text) \n","    text = re.sub(r\"calender\", \"calendar\", text)\n","    text = re.sub(r\"ios\", \"operating system\", text)\n","    text = re.sub(r\"programing\", \"programming\", text)\n","    text = re.sub(r\"bestfriend\", \"best friend\", text)\n","    text = re.sub(r\"III\", \"3\", text) \n","    text = re.sub(r\"the us\", \"america\", text)\n","    text = re.sub(r\",\", \" \", text)\n","    text = re.sub(r\"\\.\", \" \", text)\n","    text = re.sub(r\"!\", \" \", text)\n","    text = re.sub(r\"\\/\", \" \", text)\n","    text = re.sub(r\"\\^\", \" \", text)\n","    text = re.sub(r\"\\+\", \" \", text)\n","    text = re.sub(r\"\\-\", \" \", text)\n","    text = re.sub(r\"\\=\", \" \", text)\n","    text = re.sub(r\"'\", \" \", text)\n","    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n","    text = re.sub(r\":\", \" \", text)\n","    text = re.sub(r\"\\0s\", \"0\", text)\n","    \n","    text = \"\".join([c for c in text if c not in punctuation])\n","        \n","    return text"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QWVFgP7tvB6U","colab_type":"code","outputId":"f3403dfc-58e3-4a67-d8b2-881640a6033d","executionInfo":{"status":"ok","timestamp":1566053805427,"user_tz":-480,"elapsed":459103,"user":{"displayName":"Suqi Ling","photoUrl":"","userId":"17227442033461168733"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["# x_train = x_train.fillna(\" \")\n","# x_test = x_test.fillna(\" \")\n","\n","# x_train['question1'] = x_train['question1'].apply(common_words_transformation_remove_punctuation)\n","# x_train['question2'] = x_train['question2'].apply(common_words_transformation_remove_punctuation)\n","# x_test['question1'] = x_test['question1'].apply(common_words_transformation_remove_punctuation)\n","# x_test['question2'] = x_test['question2'].apply(common_words_transformation_remove_punctuation)\n","\n","# x_train.to_csv(\"/tmp/x_train.csv\", index = False)\n","# x_test.to_csv(\"/tmp/x_test.csv\", index = False)\n","\n","# x_train.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>question1</th>\n","      <th>question2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>what is the step by step guide to invest in sh...</td>\n","      <td>what is the step by step guide to invest in sh...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>what is the story of kohinoor koh i noor diamond</td>\n","      <td>what would happen if the indian government sto...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>how can i increase the speed of my internet co...</td>\n","      <td>how can internet speed be increased by hacking...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>why am i mentally very lonely how can i solve it</td>\n","      <td>find the remainder when math 23  24  math is d...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>which one dissolve in water quickly sugar  sal...</td>\n","      <td>which fish would survive in salt water</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id  ...                                          question2\n","0   0  ...  what is the step by step guide to invest in sh...\n","1   1  ...  what would happen if the indian government sto...\n","2   2  ...  how can internet speed be increased by hacking...\n","3   3  ...  find the remainder when math 23  24  math is d...\n","4   4  ...            which fish would survive in salt water \n","\n","[5 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"2-fP4Y05mptQ","colab_type":"code","outputId":"6ad80f5d-90f8-49ec-b1ac-829f0e1a7fd3","executionInfo":{"status":"ok","timestamp":1566197427124,"user_tz":-480,"elapsed":2817,"user":{"displayName":"Suqi Ling","photoUrl":"","userId":"17227442033461168733"}},"colab":{"base_uri":"https://localhost:8080/","height":174}},"source":["import nltk\n","from nltk.corpus import wordnet\n","from nltk.corpus import stopwords\n","\n","nltk.download('wordnet')\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","\n","from tqdm.auto import tqdm\n","tqdm.pandas()\n","\n","import time\n","\n","def get_time():\n","  seconds = time.time()\n","  named_tuple = time.gmtime(seconds) # get struct_time\n","  hour = named_tuple.tm_hour + 8\n","  time_str = str(hour) + ':' + str(named_tuple.tm_min) + ':' + str(named_tuple.tm_sec)\n","  return time_str\n","\n","#stemming\n","def stm(tokens):\n","  stemmer = nltk.stem.PorterStemmer()\n","  return [stemmer.stem(token) for token in tokens]\n","\n","#lemmatize\n","def get_wordnet_pos(treebank_tag):\n","  \"\"\"\n","  return WORDNET POS compliance to WORDENT lemmatization (a,n,r,v) \n","  \"\"\"\n","  if treebank_tag.startswith('J'):\n","    return wordnet.ADJ\n","  elif treebank_tag.startswith('V'):\n","    return wordnet.VERB\n","  elif treebank_tag.startswith('N'):\n","    return wordnet.NOUN\n","  elif treebank_tag.startswith('R'):\n","    return wordnet.ADV\n","  else:\n","    # As default pos in lemmatization is Noun\n","    return wordnet.NOUN\n","\n","\n","def lmtz(tokens):\n","  lemmatizer = nltk.stem.WordNetLemmatizer()\n","  # find the pos tagginf for each tokens [('What', 'WP'), ('can', 'MD'), ('I', 'PRP') ....\n","  pos_tokens = nltk.pos_tag(tokens)\n","  return [lemmatizer.lemmatize(word,get_wordnet_pos(pos_tag)) for (word, pos_tag) in pos_tokens]\n","\n","#stop_words\n","from nltk.corpus import stopwords\n","def stwd(tokens):\n","  stop_words = set(stopwords.words(\"english\"))\n","  return [token for token in tokens if not token in stop_words]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1j_fbAWO8WZW","colab_type":"code","outputId":"156cf647-2019-4736-df3b-38eaf819a276","executionInfo":{"status":"ok","timestamp":1566197446876,"user_tz":-480,"elapsed":13541,"user":{"displayName":"Suqi Ling","photoUrl":"","userId":"17227442033461168733"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["\n","with open('/tmp/x_test.csv', 'wb') as f:\n","  request = gcs_service.objects().get_media(bucket=bucket_name,\n","                                            object='test.csv')\n","  media = MediaIoBaseDownload(f, request)\n","\n","  done = False\n","  while not done:\n","    # _ is a placeholder for a progress object that we ignore.\n","    # (Our file is small, so we skip reporting progress.)\n","    _, done = media.next_chunk()\n","    \n","print('Download complete')\n","\n","x_test = pd.read_csv('/tmp/x_test.csv')\n","\n","x_test.head()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Download complete\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>test_id</th>\n","      <th>question1</th>\n","      <th>question2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>How does the Surface Pro himself 4 compare wit...</td>\n","      <td>Why did Microsoft choose core m3 and not core ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Should I have a hair transplant at age 24? How...</td>\n","      <td>How much cost does hair transplant require?</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>What but is the best way to send money from Ch...</td>\n","      <td>What you send money to China?</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Which food not emulsifiers?</td>\n","      <td>What foods fibre?</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>How \"aberystwyth\" start reading?</td>\n","      <td>How their can I start reading?</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   test_id  ...                                          question2\n","0        0  ...  Why did Microsoft choose core m3 and not core ...\n","1        1  ...        How much cost does hair transplant require?\n","2        2  ...                      What you send money to China?\n","3        3  ...                                  What foods fibre?\n","4        4  ...                     How their can I start reading?\n","\n","[5 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"UA0PJ2pk2qje","colab_type":"code","outputId":"aca9b247-4ce7-48c2-bcb1-a4e859baf7ff","executionInfo":{"status":"ok","timestamp":1566055751094,"user_tz":-480,"elapsed":1571626,"user":{"displayName":"Suqi Ling","photoUrl":"","userId":"17227442033461168733"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["# x_train_tk = x_train\n","\n","# del x_train\n","\n","# x_train_tk['question1'] = x_train_tk['question1'].apply(nltk.word_tokenize)\n","# x_train_tk['question2'] = x_train_tk['question2'].apply(nltk.word_tokenize)\n","\n","# x_train_tk.to_csv(\"/tmp/x_train_tk.csv\", index = False)\n","# print(\"x_train tokenized\")\n","\n","# x_train_stm = x_train_tk\n","# x_train_stm['question1'] = x_train_stm['question1'].apply(stm)\n","# x_train_stm['question2'] = x_train_stm['question2'].apply(stm)\n","\n","# x_train_stm.to_csv(\"/tmp/x_train_stm.csv\", index = False)\n","# print(\"x_train stemming complete\")\n","\n","# x_train_lmtz = x_train_tk\n","# x_train_lmtz['question1'] = x_train_lmtz['question1'].apply(stm)\n","# x_train_lmtz['question2'] = x_train_lmtz['question2'].apply(stm)\n","\n","# x_train_lmtz.to_csv(\"/tmp/x_train_lmtz.csv\", index = False)\n","# print(\"x_train lemmatizing complete\")\n","\n","# x_train_stwd = x_train_tk\n","# x_train_stwd['question1'] = x_train_stwd['question1'].apply(stm)\n","# x_train_stwd['question2'] = x_train_stwd['question2'].apply(stm)\n","\n","# x_train_stwd.to_csv(\"/tmp/x_train_stwd.csv\", index = False)\n","# print(\"x_train remove stop words complete\")\n","\n","# del x_train_tk, x_train_stm, x_train_lmtz\n","\n","# x_train_stwd_stm = x_train_stwd\n","# x_train_stwd_stm['question1'] = x_train_stwd_stm['question1'].apply(stm)\n","# x_train_stwd_stm['question2'] = x_train_stwd_stm['question2'].apply(stm)\n","\n","# x_train_stwd_stm.to_csv(\"/tmp/x_train_stwd_stm.csv\", index = False)\n","# print(\"x_train stop words and stemming complete\")\n","\n","# x_train_stwd_lmtz = x_train_stwd\n","# x_train_stwd_lmtz['question1'] = x_train_stwd_lmtz['question1'].apply(lmtz)\n","# x_train_stwd_lmtz['question2'] = x_train_stwd_lmtz['question2'].apply(lmtz)\n","\n","# x_train_stwd_lmtz.to_csv(\"/tmp/x_train_stwd_lmtz.csv\", index = False)\n","# print(\"x_train stop words and lemmatizing complete\")\n","\n","# del x_train_stwd, x_train_stwd_stm, x_train_stwd_lmtz\n","\n","# print(\"x_train pre-processing complete\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["x_train tokenized\n","x_train stemming complete\n","x_train lemmatizing complete\n","x_train remove stop words complete\n","x_train stop words and stemming complete\n","x_train stop words and lemmatizing complete\n","x_train pre-processing complete\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aJ6Zi3Lis-xp","colab_type":"code","outputId":"bd1b641f-feea-46d7-abda-0c16ebc38e37","executionInfo":{"status":"ok","timestamp":1566199004226,"user_tz":-480,"elapsed":436521,"user":{"displayName":"Suqi Ling","photoUrl":"","userId":"17227442033461168733"}},"colab":{"base_uri":"https://localhost:8080/","height":274}},"source":["x_test = x_test.fillna(\" \")\n","\n","time_str = get_time()\n","print(\"x_test cleaning start at \" + time_str)\n","\n","x_test['question1'] = x_test['question1'].progress_apply(common_words_transformation_remove_punctuation)\n","x_test['question2'] = x_test['question2'].progress_apply(common_words_transformation_remove_punctuation)\n","print(\"x_test cleaned\")\n","x_test.head()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["x_test cleaning start at 15:9:29\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"41db0c5f01ff4da6a984da9ed1d2f9b5","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=2345796), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1c0f50ba5cb847ce882c5ca65f6ecc17","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=2345796), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","x_test cleaned\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>test_id</th>\n","      <th>question1</th>\n","      <th>question2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>how does the surface pro himself 4 compare wit...</td>\n","      <td>why did microsoft choose core m3 and not core ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>should i have a hair transplant at age 24 how ...</td>\n","      <td>how much cost does hair transplant require</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>what but is the best way to send money from ch...</td>\n","      <td>what you send money to china</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>which food not emulsifiers</td>\n","      <td>what foods fibre</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>how aberystwyth start reading</td>\n","      <td>how their can i start reading</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   test_id  ...                                          question2\n","0        0  ...  why did microsoft choose core m3 and not core ...\n","1        1  ...        how much cost does hair transplant require \n","2        2  ...                      what you send money to china \n","3        3  ...                                  what foods fibre \n","4        4  ...                     how their can i start reading \n","\n","[5 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"ZNHpEYEItpCV","colab_type":"code","outputId":"9c9d8313-bb45-490f-b9aa-4e98bf5c633f","executionInfo":{"status":"ok","timestamp":1566201132989,"user_tz":-480,"elapsed":2085366,"user":{"displayName":"Suqi Ling","photoUrl":"","userId":"17227442033461168733"}},"colab":{"base_uri":"https://localhost:8080/","height":256}},"source":["x_test_stm = x_test\n","\n","def stm(text):\n","  tokens = nltk.word_tokenize(text)\n","  stemmer = nltk.stem.PorterStemmer()\n","  return \" \".join([stemmer.stem(token) for token in tokens])\n","\n","time_str = get_time()\n","print(\"x_test stemming start at \" + time_str)\n","x_test_stm['question1'] = x_test_stm['question1'].progress_apply(stm)\n","x_test_stm['question2'] = x_test_stm['question2'].progress_apply(stm)\n","x_test_stm.head()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["x_test stemming start at 15:17:29\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"92451f49a53b435c8018cab2694878d8","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=2345796), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1d10ab7d8c734475b542ca0bbc6778d1","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=2345796), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>test_id</th>\n","      <th>question1</th>\n","      <th>question2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>how doe the surfac pro himself 4 compar with i...</td>\n","      <td>whi did microsoft choos core m3 and not core i...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>should i have a hair transplant at age 24 how ...</td>\n","      <td>how much cost doe hair transplant requir</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>what but is the best way to send money from ch...</td>\n","      <td>what you send money to china</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>which food not emulsifi</td>\n","      <td>what food fibr</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>how aberystwyth start read</td>\n","      <td>how their can i start read</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   test_id  ...                                          question2\n","0        0  ...  whi did microsoft choos core m3 and not core i...\n","1        1  ...           how much cost doe hair transplant requir\n","2        2  ...                       what you send money to china\n","3        3  ...                                     what food fibr\n","4        4  ...                         how their can i start read\n","\n","[5 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"vs3AwfQ04URR","colab_type":"code","outputId":"ce223b55-d0a5-4bce-9793-c9b6a2daf706","executionInfo":{"status":"ok","timestamp":1566201573610,"user_tz":-480,"elapsed":19558,"user":{"displayName":"Suqi Ling","photoUrl":"","userId":"17227442033461168733"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["x_test_stm.to_csv(\"/tmp/x_test_stm_cvt.csv\", index = False)\n","upload_to_GCS('x_test_stm_cvt.csv')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["x_test_stm_cvt.csv uploaded\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lP4NgQaX44eC","colab_type":"code","outputId":"4cc470de-5864-4901-eaac-b6b204084610","executionInfo":{"status":"ok","timestamp":1566207080828,"user_tz":-480,"elapsed":5362644,"user":{"displayName":"Suqi Ling","photoUrl":"","userId":"17227442033461168733"}},"colab":{"base_uri":"https://localhost:8080/","height":256}},"source":["x_test_lmtz = x_test\n","\n","def lmtz(text):\n","  tokens = nltk.word_tokenize(text)\n","  lemmatizer = nltk.stem.WordNetLemmatizer()\n","  # find the pos tagginf for each tokens [('What', 'WP'), ('can', 'MD'), ('I', 'PRP') ....\n","  pos_tokens = nltk.pos_tag(tokens)\n","  return [lemmatizer.lemmatize(word,get_wordnet_pos(pos_tag)) for (word, pos_tag) in pos_tokens]\n","\n","time_str = get_time()\n","print(\"x_test lemmatizmming start at \" + time_str)\n","x_test_lmtz['question1'] = x_test_lmtz['question1'].progress_apply(lmtz)\n","x_test_lmtz['question2'] = x_test_lmtz['question2'].progress_apply(lmtz)\n","x_test_lmtz.head()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["x_test lemmatizmming start at 16:1:59\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e5041919ccc443a8ba57d9f986606d83","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=2345796), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9633df302df8457aa244ca5d7050cc9d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=2345796), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>test_id</th>\n","      <th>question1</th>\n","      <th>question2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>[how, doe, the, surfac, pro, himself, 4, compa...</td>\n","      <td>[whi, do, microsoft, choos, core, m3, and, not...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>[should, i, have, a, hair, transplant, at, age...</td>\n","      <td>[how, much, cost, doe, hair, transplant, requir]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>[what, but, be, the, best, way, to, send, mone...</td>\n","      <td>[what, you, send, money, to, china]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>[which, food, not, emulsifi]</td>\n","      <td>[what, food, fibr]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>[how, aberystwyth, start, read]</td>\n","      <td>[how, their, can, i, start, read]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   test_id  ...                                          question2\n","0        0  ...  [whi, do, microsoft, choos, core, m3, and, not...\n","1        1  ...   [how, much, cost, doe, hair, transplant, requir]\n","2        2  ...                [what, you, send, money, to, china]\n","3        3  ...                                 [what, food, fibr]\n","4        4  ...                  [how, their, can, i, start, read]\n","\n","[5 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"8pglmJgsOWT-","colab_type":"code","outputId":"af05aa3d-a5f7-40f2-e793-163ca378bdc2","executionInfo":{"status":"ok","timestamp":1566207278615,"user_tz":-480,"elapsed":30228,"user":{"displayName":"Suqi Ling","photoUrl":"","userId":"17227442033461168733"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["x_test_lmtz.to_csv(\"/tmp/x_test_lmtz_cvt.csv\", index = False)\n","upload_to_GCS('x_test_lmtz_cvt.csv')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["x_test_lmtz_cvt.csv uploaded\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5taiuBShLDOu","colab_type":"code","outputId":"51ebba32-7d80-4864-a036-dedfb8d03d85","executionInfo":{"status":"error","timestamp":1566152462906,"user_tz":-480,"elapsed":524290,"user":{"displayName":"Suqi Ling","photoUrl":"","userId":"17227442033461168733"}},"colab":{"base_uri":"https://localhost:8080/","height":507}},"source":["x_test = x_test.fillna(\" \")\n","\n","time_str = get_time()\n","print(\"x_test cleaning start at \" + time_str)\n","\n","x_test['question1'] = x_test['question1'].progress_apply(common_words_transformation_remove_punctuation)\n","x_test['question2'] = x_test['question2'].progress_apply(common_words_transformation_remove_punctuation)\n","print(\"x_test cleaned\")\n","\n","x_test_tk = x_test\n","\n","del x_test\n","\n","time_str = get_time()\n","print(\"x_test tokenizing start at \" + time_str)\n","\n","x_test_tk['question1'] = x_test_tk['question1'].progress_apply(nltk.word_tokenize)\n","x_test_tk['question2'] = x_test_tk['question2'].progress_apply(nltk.word_tokenize)\n","\n","x_test_tk.to_csv(\"/tmp/x_test_tk.csv\", index = False)\n","print(\"x_test tokenized\")\n","\n","x_test_stm = x_test_tk\n","x_test_stm['question1'] = x_test_stm['question1'].apply(stm)\n","x_test_stm['question2'] = x_test_stm['question2'].apply(stm)\n","\n","x_test_stm.to_csv(\"/tmp/x_test_stm.csv\", index = False)\n","del x_test_stm\n","print(\"x_test stemming complete\")\n","\n","x_test_lmtz = x_test_tk\n","x_test_lmtz['question1'] = x_test_lmtz['question1'].apply(stm)\n","x_test_lmtz['question2'] = x_test_lmtz['question2'].apply(stm)\n","\n","x_test_lmtz.to_csv(\"/tmp/x_test_lmtz.csv\", index = False)\n","del x_test_lmtz\n","print(\"x_test lemmatizing complete\")\n","\n","x_test_stwd = x_test_tk\n","\n","time_str = get_time()\n","print(\"x_test stop words removing start at \" + time_str)\n","\n","x_test_stwd['question1'] = x_test_stwd['question1'].progress_apply(stm)\n","x_test_stwd['question2'] = x_test_stwd['question2'].progress_apply(stm)\n","\n","x_test_stwd.to_csv(\"/tmp/x_test_stwd.csv\", index = False)\n","print(\"x_test remove stop words complete\")\n","\n","del x_test_tk\n","\n","# x_test_stwd_stm = x_test_stwd\n","# x_test_stwd_stm['question1'] = x_test_stwd_stm['question1'].apply(stm)\n","# x_test_stwd_stm['question2'] = x_test_stwd_stm['question2'].apply(stm)\n","\n","# x_test_stwd_stm.to_csv(\"/tmp/x_test_stwd_stm.csv\", index = False)\n","# del x_test_stwd_stm\n","# print(\"x_test stop words and stemming complete\")\n","\n","x_test_stwd_lmtz = x_test_stwd\n","time_str = get_time()\n","print(\"x_test stop words and lemmatizing start at \" + time_str)\n","x_test_stwd_lmtz['question1'] = x_test_stwd_lmtz['question1'].progress_apply(lmtz)\n","x_test_stwd_lmtz['question2'] = x_test_stwd_lmtz['question2'].progress_apply(lmtz)\n","\n","x_test_stwd_lmtz.to_csv(\"/tmp/x_test_stwd_lmtz.csv\", index = False)\n","del x_test_stwd_lmtz\n","time_str = get_time()\n","print(\"x_test stop words and lemmatizing complete at \"+ time_str)\n","\n","del x_test_stwd\n","\n","print(\"x_test pre-processing complete\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["x_test cleaning start at 26:12:20\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e9aeda9f892341c99d60726ba54dda4a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=2345796), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d618615bd7884335bbac8ab68443b2d9","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=2345796), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","x_test cleaned\n","x_test tokenizing start at 26:19:18\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3a84e912f484460b8f341bf029bff8bb","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=2345796), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-dcd7ef225bd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x_test tokenizing start at \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtime_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mx_test_tk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test_tk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mx_test_tk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test_tk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    658\u001b[0m                 \u001b[0;31m# Apply the provided function (in **kwargs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m                 \u001b[0;31m# on the df using our wrapper (which provides bar updating)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m                 \u001b[0;31m# Close bar and return pandas calculation result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3589\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3590\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3591\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3593\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    654\u001b[0m                     \u001b[0;31m# take a fast or slow code path; so stop when t.total==t.n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m                 \u001b[0;31m# Apply the provided function (in **kwargs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \"\"\"\n\u001b[1;32m    128\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     return [token for sent in sentences\n\u001b[0m\u001b[1;32m    130\u001b[0m             for token in _treebank_word_tokenizer.tokenize(sent)]\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     return [token for sent in sentences\n\u001b[0;32m--> 130\u001b[0;31m             for token in _treebank_word_tokenizer.tokenize(sent)]\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/treebank.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, convert_parentheses, return_str)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mregexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubstitution\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPUNCTUATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubstitution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# Handles parentheses.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/re.py\u001b[0m in \u001b[0;36m_subx\u001b[0;34m(pattern, template)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_subx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;31m# internal: pattern.sub/subn implementation helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m     \u001b[0mtemplate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_compile_repl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# literal replacement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"moX6-qSC3kav","colab_type":"code","colab":{}},"source":["from googleapiclient.http import MediaFileUpload\n","\n","# files = ['x_test_stwd_lmtz.csv']\n","\n","def upload_to_GCS(file_name):\n","  file_path = '/tmp/' + file_name\n","  \n","  media = MediaFileUpload(file_path, \n","                          mimetype='text/csv',\n","                          resumable=True)\n","\n","  request = gcs_service.objects().insert(bucket=bucket_name, \n","                                         name=file_name,\n","                                         media_body=media)\n","\n","  response = None\n","  while response is None:\n","    # _ is a placeholder for a progress object that we ignore.\n","    # (Our file is small, so we skip reporting progress.)\n","    _, response = request.next_chunk()\n","  print(file_name + ' uploaded')\n","    \n","# [upload_to_GCS(file_name) for file_name in files]\n","\n","# print('Upload complete')"],"execution_count":0,"outputs":[]}]}